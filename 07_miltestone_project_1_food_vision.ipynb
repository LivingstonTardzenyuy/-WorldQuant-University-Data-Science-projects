{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LivingstonTardzenyuy/-WorldQuant-University-Data-Science-projects/blob/main/07_miltestone_project_1_food_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Milestone Project 1: Food Vision Big."
      ],
      "metadata": {
        "id": "4FdMi9-VIx6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## checkout GPU.\n",
        "* Google Colab offers free GPUs, howerver, not all of them are compatiable with mixed precision training.\n",
        "\n",
        "Google Colab offers:\n",
        "* K80 (not compatible with mixed precision training)\n",
        "* P100 (compatible with mixed precision training)\n",
        "* T4 (compatible with mixed precision training)"
      ],
      "metadata": {
        "id": "jeKsIuR4JG_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W84myl8AKAo3",
        "outputId": "0054eaee-badc-44e4-8294-b1172bf79e26"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-1fe89c69-4615-ad3d-88cb-2450c240208e)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get helper functions.\n",
        "\n",
        "We've created helper functions in the past. Now we will call them and continue utilizing them..\n",
        "https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/helper_functions.py"
      ],
      "metadata": {
        "id": "B3NJRGd7LMwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download helper functions script.\n",
        "\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inyjQl1TMhdJ",
        "outputId": "8ee082f1-ce0e-410f-ad35-c14ca95a2ef4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-03 01:44:08--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-03 01:44:08 (49.3 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import a series of helper functions for the notebook\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "wG4sdG-LMnur"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get TensorFlow Datasets.\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "-S2xo5_gNbdc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all avialable datasets.\n",
        "datasets_list = tfds.list_builders()\n",
        "print(\"food101\" in datasets_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqoFtKBvQiH2",
        "outputId": "4cdec984-f0d9-4ef6-958a-7987d4ca874e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the data (takes 5-6 minues in Google Colab).\n",
        "(train_data, test_data), ds_info = tfds.load(name=\"food101\",\n",
        "                                               split=[\"train\", \"validation\"],\n",
        "                                               shuffle_files=True,\n",
        "                                               as_supervised=True,    # data get return in tuple.\n",
        "                                               with_info=True\n",
        "                                             )"
      ],
      "metadata": {
        "id": "NdbcYHbPQwzG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Features of Food101 from TFDS.\n",
        "ds_info.features"
      ],
      "metadata": {
        "id": "AZTzom3qTsdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class names.\n",
        "class_names = ds_info.features[\"label\"].names\n",
        "class_names[:10]"
      ],
      "metadata": {
        "id": "a4g0i8eQT7pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring the Food101 data from TensorFlow Datasets.\n",
        "\n",
        "To become one with our data, we want to find:\n",
        "\n",
        "* Class names\n",
        "* The shape of our input data (image tensors)\n",
        "* The datatype of our input data.\n",
        "* What the labels look like (e.g are they one-hot encoded or are they label encoded)\n",
        "* Do the labels match up with the class names ?.\n"
      ],
      "metadata": {
        "id": "qDiQ15hAURln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take one sample of the train data.\n",
        "train_one_sample = train_data.take(1)    # samples are in format (image_tensor, label)\n",
        "train_one_sample"
      ],
      "metadata": {
        "id": "7PbBR8-SU9pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output infor about our training sample.\n",
        "for image, label in train_one_sample:\n",
        "  print(f\"Image shape: {image.shape}\")\n",
        "  print(f\"Image datatype: {image.dtype}\")\n",
        "  print(f\"Target class from class_names: {class_names[label]}\")\n",
        "  print(f\"Target class from label: {label}\")"
      ],
      "metadata": {
        "id": "z3wF7RbQVATD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What does our image tensor from TFDS's Food101 look like ?.\n",
        "image"
      ],
      "metadata": {
        "id": "P50NJlcAWJBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What are the min and max values of our image tensor ?.\n",
        "import tensorflow as tf\n",
        "tf.reduce_min(image), tf.reduce_max(image)"
      ],
      "metadata": {
        "id": "ePW67F8hWslG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot an image from TensorFlow Datasets"
      ],
      "metadata": {
        "id": "eDQekBnZW5G5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot an image tensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.title(class_names[label.numpy()])"
      ],
      "metadata": {
        "id": "jU_9seWWXbIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create preprocessing functions for our data.\n",
        "\n",
        "Neural networks perform best when are data is in a certain way. eg. Batched, normalized etc.\n",
        "\n",
        "However, not all data (including data from TensorFlow Datasets) is in the way we want it.\n",
        "\n",
        "So in order to get it ready for our neural network we'll have to write preprocessing function and map it with our data.\n",
        "\n",
        "What we know about our data:\n",
        "\n",
        "* In 'unit8' datatype.\n",
        "* Comprised of all different size of tensors (different sized images)\n",
        "* Not scaled (the pixel values are between 0-255)\n",
        "\n",
        "\n",
        "What we know models like:\n",
        "* Data in 'float32' dtype (or for mixed precision 'float16' and 'float32')\n",
        "* For batches, TensorFlow likes all of the tensors within a batch to be of the same size.\n",
        "* Scaled (values between 0-1) also called Normalized/scaling tensors generally perform better.\n",
        "\n",
        "With thses points in mind, we've got a few things to tackle with a preprocesing function.\n",
        "\n",
        "Since we've been using EfficientNetBx pretrained model from tf.keras.applications we don't need to rescale our data(these architectures have rescaling built-in).\n",
        "\n",
        "This means our function have to\n",
        "\n",
        "* reshape our iamges to same size.\n",
        "* Convert the dtype of our image tensors from 'unit8' to float32.\n"
      ],
      "metadata": {
        "id": "931uPW7MZvql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a function for preprocessing our image.\n",
        "def preprocess_img(image, label, img_shape = 224):\n",
        "  \"\"\"\n",
        "    Converts image datatype from 'uint8' to 'float32' and reshapes image to [img_shape, img_shape, color_channels].\n",
        "  \"\"\"\n",
        "\n",
        "  # reshape our image size.\n",
        "  image = tf.image.resize(image, [img_shape, img_shape])\n",
        "\n",
        "  # converting our images from unit8 to float32.\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  # image = image/255. # Scale image values. But its not required here since EfficientNetB0 already have rescalling build in.\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "8rsUbAR1bTFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess a single sample image and check the outputs.\n",
        "preprocessed_img = preprocess_img(image, label)\n",
        "print(f\"Image before preprocessing:\\n {image[:2]}...,  \\nShape: {image}, \\nDatatype: {image.dtype}\")\n",
        "print(f\"Image after preprocessing:\\n {preprocessed_img[0][:2]}...,  \\nShape: {preprocessed_img[0].shape}, \\nDatatype: {preprocessed_img[0].dtype}\")\n"
      ],
      "metadata": {
        "id": "n7vSZLxJdJ3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch & prepare datasets.\n",
        "\n",
        "We're now going to make our data input pipeline run really fast.\n",
        "\n",
        "For more resources on this: https://www.tensorflow.org/guide/data_performance"
      ],
      "metadata": {
        "id": "wiQuSCEzdSe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map preprocessing function to training (and parallelize)\n",
        "train_data = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Shuffle train_data and turn it into batches and prefetch.\n",
        "train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Map preprocessing function to test data.\n",
        "test_data = test_data.map(preprocess_img, num_parallel_calls=tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "_WLRqGDZ_d2i"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data"
      ],
      "metadata": {
        "id": "xemNwDL3Bv0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Create modellling callbacks.\n",
        "\n",
        "  We're going to create a couple of callbacks to help us while our model trains:\n",
        "\n",
        "  * TensorBoard callback to log training results (so we can visualize them later if need be)\n",
        "\n",
        "  * ModelCheckpoint callback to save our model progress after feature extraction."
      ],
      "metadata": {
        "id": "Wi_k8z4sB9uX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensorboard callback. (inport from helper_functions.py)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create ModelCheckpoint callback to save a model's progress during training.\n",
        "checkpoint_path = \"model_checkpoints/cp.weights.h5\"\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor=\"val_accuracy\",\n",
        "    save_best_only=True,\n",
        "    verbose=0\n",
        ")\n"
      ],
      "metadata": {
        "id": "KEDA7_-9awSY"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup mixed precision traning.\n",
        "\n",
        "First and foremost, for a deeper understanding of mixed precision traning. We'll see https://www.tensorflow.org/guide/mixed_precision\n",
        "\n",
        "Mixed precision utilizes a combination of Float16 and Float32 to speed up performance."
      ],
      "metadata": {
        "id": "B1y9WMn8duK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trun on mixed precision\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "mixed_precision.set_global_policy(\"mixed_float16\")"
      ],
      "metadata": {
        "id": "8dg_WDtadC-j"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint"
      ],
      "metadata": {
        "id": "q6MbbDNBeMuz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "932668dd-ff8e-4fe2-df67-bff2c1d4761f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.model_checkpoint.ModelCheckpoint at 0x788169073e50>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Base model(Feature Extraction)"
      ],
      "metadata": {
        "id": "QuygoVqLfhl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "#Download base model and freeze underlying layers\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top = False)\n",
        "base_model.trainable = False\n",
        "INPUT_SHAPE = [224, 224, 3]\n",
        "# Create a functional model.\n",
        "inputs = layers.Input(shape=INPUT_SHAPE)\n",
        "# Note: EfficientNetBX models already have Rescaling layers build-int but if we're using a d/f model we'll neeed to include Rescalling layer here.\n",
        "# x = Rescalling(1/255)(x)\n",
        "x = base_model(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(len(class_names))(x)\n",
        "outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)    # We include the dtype here since we've setup mixed precision.\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "GVAXR5AdgXZO"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model.\n",
        "model.compile(\n",
        "    loss = \"sparse_categorical_crossentropy\",    # We change our loss to Sparsh_categorical_crossentropy since our labels are as int.\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics = [\"accuracy\"]\n",
        "    )"
      ],
      "metadata": {
        "id": "Kr910B9Giw_4"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "SAioSL5kjoh1",
        "outputId": "a5869bf5-d965-4f78-cc8b-be12bb1ece52"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m4,049,571\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)                 │         \u001b[38;5;34m129,381\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ cast_4 (\u001b[38;5;33mCast\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ softmax_float32 (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">129,381</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ cast_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ softmax_float32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,178,952\u001b[0m (15.94 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,178,952</span> (15.94 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m129,381\u001b[0m (505.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,381</span> (505.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking layers dtype policies(Are we using mixed precision)"
      ],
      "metadata": {
        "id": "Vha0DeIrjpoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dtype_policy.\n",
        "for layer in model.layers:\n",
        "  print(layer.name, layer.trainable, layer.dtype_policy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0Dvk_sbkG-J",
        "outputId": "1b32c4de-b215-443e-876d-07d256f2ecf4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_layer_4 True <DTypePolicy \"mixed_float16\">\n",
            "efficientnetb0 False <DTypePolicy \"mixed_float16\">\n",
            "global_average_pooling2d_1 True <DTypePolicy \"mixed_float16\">\n",
            "dense_1 True <DTypePolicy \"mixed_float16\">\n",
            "softmax_float32 True <DTypePolicy \"float32\">\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Fitting our model.\n",
        "model_history = model.fit(\n",
        "    train_data,\n",
        "    epochs = 5,\n",
        "    steps_per_epoch = len(train_data),\n",
        "    validation_data = test_data,\n",
        "    validation_steps = int(0.15 * len(test_data)),\n",
        "    callbacks = [create_tensorboard_callback(\"training_logs\", \"efficientnetb0_feature_extraction\"), model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "9ut8EZcUkM3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68c012c9-f4f5-4b9d-dfb7-2c71f9e4b7ac"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: training_logs/efficientnetb0_feature_extraction/20250303-021615\n",
            "Epoch 1/5\n",
            "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 82ms/step - accuracy: 0.4765 - loss: 2.2828 - val_accuracy: 0.6920 - val_loss: 1.1453\n",
            "Epoch 2/5\n",
            "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 71ms/step - accuracy: 0.6659 - loss: 1.2945 - val_accuracy: 0.7158 - val_loss: 1.0451\n",
            "Epoch 3/5\n",
            "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 73ms/step - accuracy: 0.7035 - loss: 1.1376 - val_accuracy: 0.7233 - val_loss: 0.9952\n",
            "Epoch 4/5\n",
            "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 79ms/step - accuracy: 0.7261 - loss: 1.0390 - val_accuracy: 0.7270 - val_loss: 0.9812\n",
            "Epoch 5/5\n",
            "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 76ms/step - accuracy: 0.7423 - loss: 0.9775 - val_accuracy: 0.7309 - val_loss: 0.9592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model on test_dataset.\n",
        "results_feature_extract_model = model.evaluate(test_data)\n",
        "results_feature_extract_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA5v-OUpzWSk",
        "outputId": "41599941-90a1-4d60-d8ad-e227b0133393"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 74ms/step - accuracy: 0.7335 - loss: 0.9653\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9618264436721802, 0.7388119101524353]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving our build model locally.\n",
        "model_save = model.save(\"model_checkpoints/feature_extract_model.keras\")"
      ],
      "metadata": {
        "id": "eVboABQ0xiZp"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load our save model.\n",
        "loaded_model = tf.keras.models.load_model(\"model_checkpoints/feature_extract_model.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fV9I-W1073e",
        "outputId": "98fedee6-8243-467c-fd59-25692144a48d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'loss_scale_optimizer', because it has 8 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 4 variables whereas the saved optimizer has 6 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the loaded model performance.\n",
        "loaded_model.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIjIztPD1AXU",
        "outputId": "1f17c856-eac1-4084-c8fd-ae7850974522"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 66ms/step - accuracy: 0.7337 - loss: 0.9650\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.961826503276825, 0.7388119101524353]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing our model's layer for Fine-tuning"
      ],
      "metadata": {
        "id": "8e8bwH2k1G6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloaded the save model from google storage.\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_feature_extract_model_mixed_precision.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq18ELID1fke",
        "outputId": "a6239c2d-66f9-45c3-8d46-ccd0c7ede477"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-03 02:38:12--  https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_feature_extract_model_mixed_precision.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.207, 74.125.195.207, 172.253.117.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16976857 (16M) [application/zip]\n",
            "Saving to: ‘07_efficientnetb0_feature_extract_model_mixed_precision.zip’\n",
            "\n",
            "07_efficientnetb0_f 100%[===================>]  16.19M  84.8MB/s    in 0.2s    \n",
            "\n",
            "2025-03-03 02:38:13 (84.8 MB/s) - ‘07_efficientnetb0_feature_extract_model_mixed_precision.zip’ saved [16976857/16976857]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and evaluate downloaded GS model.\n",
        "loaded_model = tf.keras.models.load_model(\"07_efficientnetb0_feature_extract_model_mixed_precision.zip\")\n",
        "loaded_model.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "Fcr4-okQ2B3p",
        "outputId": "63e771e4-f4bf-4b6c-ba73-f5043c72f29e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "File format not supported: filepath=07_efficientnetb0_feature_extract_model_mixed_precision.zip. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(07_efficientnetb0_feature_extract_model_mixed_precision.zip, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-1af2d8cf84da>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load and evaluate downloaded GS model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"07_efficientnetb0_feature_extract_model_mixed_precision.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    204\u001b[0m         )\n\u001b[1;32m    205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0;34mf\"File format not supported: filepath={filepath}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;34m\"Keras 3 only supports V3 `.keras` files and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: File format not supported: filepath=07_efficientnetb0_feature_extract_model_mixed_precision.zip. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(07_efficientnetb0_feature_extract_model_mixed_precision.zip, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting a summary of the downloaded model.\n",
        "loaded_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "qEU3skVW2Kqv",
        "outputId": "71e73dd0-03ff-4fff-f4ac-e061a1ed9173"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m4,049,571\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)                 │         \u001b[38;5;34m129,381\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ cast_6 (\u001b[38;5;33mCast\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ softmax_float32 (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">129,381</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ cast_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ softmax_float32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,308,339\u001b[0m (16.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,308,339</span> (16.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m129,381\u001b[0m (505.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,381</span> (505.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m129,387\u001b[0m (505.43 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,387</span> (505.43 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seting all the layers .trianable variable in the loaded model to True.\n",
        "base_model.trainable = True"
      ],
      "metadata": {
        "id": "tBVGx_Za3mRB"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers[:-10]:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "MRVeFfUm7IvG"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the dtype_policy of the layers in our loaded model.\n",
        "for layer in loaded_model.layers:\n",
        "  print(layer.name, layer.trainable, layer.dtype_policy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RZIdlIW3vyo",
        "outputId": "7e7c8d04-fdc5-4c0e-9ae0-78ce29600402"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_layer_4 True <DTypePolicy \"mixed_float16\">\n",
            "efficientnetb0 False <DTypePolicy \"mixed_float16\">\n",
            "global_average_pooling2d_1 True <DTypePolicy \"mixed_float16\">\n",
            "dense_1 True <DTypePolicy \"mixed_float16\">\n",
            "softmax_float32 True <DTypePolicy \"float32\">\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up EarlyStopping callback to stop training.\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor=\"val_accuracy\",\n",
        "                               patience=3,\n",
        "                               restore_best_weights=True\n",
        "                               )"
      ],
      "metadata": {
        "id": "IkM0Deb831_q"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a modelCheckpoint callbakc to save best model during fine-tuning.\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    \"model_checkpoints/fine_tune_model.h5\",\n",
        "    save_best_only=True,\n",
        "    monitor=\"val_loss\"\n",
        ")"
      ],
      "metadata": {
        "id": "tqKlv04A4PN5"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile our model.\n",
        "loaded_model.compile(\n",
        "    loss = \"sparse_categorical_crossentropy\",           # Since our labels are integers represinting the class index.\n",
        "    optimizer = tf.keras.optimizers.Adam(0.0001),\n",
        "    metrics = [\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "QXd_TAC149lb"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the create_tensorboard_callback function directly in your script\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback\n"
      ],
      "metadata": {
        "id": "1O9AxdkS8khD"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune for 5 more epochs\n",
        "fine_tune_epochs = 3\n",
        "total_epochs = 5 + fine_tune_epochs\n",
        "total_epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HxicFxf57hw",
        "outputId": "1325f123-c000-49d8-d8fd-cb0f15250f54"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the fine-tune model.\n",
        "fine_tune_history = loaded_model.fit(\n",
        "    train_data,\n",
        "    epochs = total_epochs,\n",
        "    steps_per_epoch = len(train_data),\n",
        "    validation_data = test_data,\n",
        "    initial_epoch = model_history.epoch[-1],\n",
        "    validation_steps = int(0.15 * len(test_data)),\n",
        "    callbacks = [create_tensorboard_callback(\"training_logs\", \"efficientnetb0_fine_tune\"), early_stopping, model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8RBLUqC5Qmp",
        "outputId": "f7c08c82-d13f-44a5-ed02-4558956196a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: training_logs/efficientnetb0_fine_tune/20250303-030008\n",
            "Epoch 5/8\n",
            "\u001b[1m1695/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 67ms/step - accuracy: 0.7802 - loss: 0.8393"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the fine-tune model.\n",
        "loaded_model.evaluate(test_data)"
      ],
      "metadata": {
        "id": "bfJIUX_t6Mxg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}